<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 18 Ordered Categorical Data, i.e., Likert-scales | Notes on Statistics</title>
<meta name="author" content="Alexander Pastukhov">
<meta name="description" content="One of a very popular type of response in psychology and social sciences are so-called Likert-scale response. For example, you may be asked to respond on how attractive you find a person in a...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 18 Ordered Categorical Data, i.e., Likert-scales | Notes on Statistics">
<meta property="og:type" content="book">
<meta property="og:description" content="One of a very popular type of response in psychology and social sciences are so-called Likert-scale response. For example, you may be asked to respond on how attractive you find a person in a...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 18 Ordered Categorical Data, i.e., Likert-scales | Notes on Statistics">
<meta name="twitter:description" content="One of a very popular type of response in psychology and social sciences are so-called Likert-scale response. For example, you may be asked to respond on how attractive you find a person in a...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.13/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css%20-%20style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Notes on Statistics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Precis</a></li>
<li><a class="" href="loss-functions.html"><span class="header-section-number">2</span> Loss functions</a></li>
<li><a class="" href="directed-acyclic-graphs-and-causal-reasoning.html"><span class="header-section-number">3</span> Directed Acyclic Graphs and Causal Reasoning</a></li>
<li><a class="" href="spurious-association.html"><span class="header-section-number">4</span> Multiple regression - Spurious association</a></li>
<li><a class="" href="the-haunted-dag.html"><span class="header-section-number">5</span> The haunted DAG</a></li>
<li><a class="" href="information-criteria.html"><span class="header-section-number">6</span> Information Criteria</a></li>
<li><a class="" href="bayesian-vs.-fequentist-statisics.html"><span class="header-section-number">7</span> Bayesian vs. fequentist statisics</a></li>
<li><a class="" href="mixtures.html"><span class="header-section-number">8</span> Mixtures</a></li>
<li><a class="" href="instrumental-variables.html"><span class="header-section-number">9</span> Instrumental Variables</a></li>
<li><a class="" href="parameters-combining-information-from-an-individual-with-population.html"><span class="header-section-number">10</span> Parameters: combining information from an individual with population</a></li>
<li><a class="" href="incorporating-measurement-error-a-rubber-band-metaphor.html"><span class="header-section-number">11</span> Incorporating measurement error: a rubber band metaphor</a></li>
<li><a class="" href="generalized-additive-models-as-continuous-random-effects.html"><span class="header-section-number">12</span> Generalized Additive Models as continuous random effects</a></li>
<li><a class="" href="flat-priors-the-strings-attached.html"><span class="header-section-number">13</span> Flat priors: the strings attached</a></li>
<li><a class="" href="unbiased-mean-versus-biased-variance-in-plain-english.html"><span class="header-section-number">14</span> Unbiased mean versus biased variance in plain English</a></li>
<li><a class="" href="probability-mass-versus-probability-density.html"><span class="header-section-number">15</span> Probability mass versus probability density</a></li>
<li><a class="" href="effective-degrees-of-freedom-number-of-parameters.html"><span class="header-section-number">16</span> Effective degrees of freedom / number of parameters</a></li>
<li><a class="" href="multiple-regression---masked-relationship.html"><span class="header-section-number">17</span> Multiple regression - Masked relationship</a></li>
<li><a class="active" href="ordered-categorical-data-i.e.-likert-scales.html"><span class="header-section-number">18</span> Ordered Categorical Data, i.e., Likert-scales</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/alexander-pastukhov/notes-on-statistics">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="ordered-categorical-data-i.e.-likert-scales" class="section level1" number="18">
<h1>
<span class="header-section-number">18</span> Ordered Categorical Data, i.e., Likert-scales<a class="anchor" aria-label="anchor" href="#ordered-categorical-data-i.e.-likert-scales"><i class="fas fa-link"></i></a>
</h1>
<p>One of a very popular type of response in psychology and social sciences are so-called Likert-scale response. For example, you may be asked to respond on how attractive you find a person in a photo from 1 (very unattractive) to 7 (very attractive). Or to respond how satisfied you are with a service from 1 (very unsatisfied) to 4 (very satisfied). Or rate your confidence on a 5-point scale, etc. Likert-scale responses are extremely common and are quite often analyzed via linear models (i.e., <em>t</em>-test, repeated measures ANOVA, linear-mixed models) assuming that response levels correspond directly to real numbers. The purpose of these notes is to document both technical and, more importantly, conceptual problems this approach entails.</p>
<div id="conceptualization-of-responses-internal-continuous-variable-discritized-into-external-responses-via-a-set-of-cut-points" class="section level2" number="18.1">
<h2>
<span class="header-section-number">18.1</span> Conceptualization of responses: internal continuous variable discritized into external responses via a set of cut-points<a class="anchor" aria-label="anchor" href="#conceptualization-of-responses-internal-continuous-variable-discritized-into-external-responses-via-a-set-of-cut-points"><i class="fas fa-link"></i></a>
</h2>
<p>First, let us think what responses correspond to as it will become very important once we discuss conceptual problems with a common “direct” approach of using linear models for Likert-scale data.</p>
<p>When we ask a participant to respond “On scale from 1 to 7, how attractive do you find the face in the photo?”, we assume that there is a <em>continuous</em> internal variable (for example, encoded via a neural ensemble) that represents attractiveness of a face (or our satisfaction with service, or our confidence, etc.). The strength of that representation varies in a continuous manner from its minimum (e.g., baseline firing rate, if we assume that strength is encoded by spiking rate) to maximum (maximum firing rate for that neural ensemble). When we impose a seven-point scale on a participants, we force them to discretize this continuous variable, creating a <em>many-to-one</em> mapping. In other words, a participant decides that values (intensities) within a particular range all get mapped on <em>1</em>, a different but adjacent range of higher values corresponds to <em>2</em>, etc. You can think about it as values within that range being “rounded” (regressed?) towards the mean that defines the response. Or, equivalently, you can think in terms of cut-points that define range limits. This is how the discretization is depicted in the figure below. If the signal is below the first cut point, our participant response is “1”. When it is between first and second cut points, the response is “2” and so on. When it is to the right of the last sixth cut point, it is “7”. This conceptualization means that responses are an ordered categorical variable, as any underlying intensity for a response “1” is necessarily smaller than <em>any</em> intensity for response “2” and both are smaller than, again, <em>any</em> intensity for response “3”.</p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-75-1.png" width="672"></div>
<p>As per usual, we assume that our continuous variable is noisy and its values can be described as being drawn from a normal distribution centered at the “true” intensity level<a href="ordered-categorical-data-i.e.-likert-scales.html#fn34" class="footnote-ref" id="fnref34"><sup>34</sup></a>. Here, the consistency of responses will depend on the width (standard deviation) of this distribution. The broader this distribution and / or closer it is to a cut-point, the more activity will “spill over” into adjacent regions and more variable discrete responses will be.</p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-76-1.png" width="672"></div>
<p>Given this conceptualization, our goal is to recover both the cut-points and the normal distribution using only observed responses.</p>
</div>
<div id="conceptual-problem-with-linear-models-we-change-our-mind-about-what-responses-correspond-to." class="section level2" number="18.2">
<h2>
<span class="header-section-number">18.2</span> Conceptual problem with linear models: we change our mind about what responses correspond to.<a class="anchor" aria-label="anchor" href="#conceptual-problem-with-linear-models-we-change-our-mind-about-what-responses-correspond-to."><i class="fas fa-link"></i></a>
</h2>
<p>A very common approach is to fit Likert-scale data using a linear model (a <em>t</em>-test, a repeated-measures ANOVA, linear-mixed models, etc.) while assuming that responses correspond directly to real numbers. In other words, when participants responded very unattractive”, or “not confident at all”, or “do not agree at all” they literally meant a real number <span class="math inline">\(1.0\)</span>. When they used the middle (let’s say the third) option “neither agree, nor disagree” they literally meant <span class="math inline">\(3.0\)</span>. This assumption appears to simplify our life dramatically but at the expense of changing the narrative.</p>
<p>Recall that our original (and very intuitive) conceptualization was that responses reflect a many-to-one mapping between an underlying continuous variable and a discrete (ordered categorical) response. But by converting them directly to numbers and using them as an outcome variable of a linear model we assume a <em>one-to-one</em> mapping between the internal variable and observed responses. This means that from a linear model point of view, for a 7-point Likert scale <em>any</em> real value is a valid and possible response and therefore participant <em>could have</em> responded with 6.5, 3.14, or 2.71828 but, for whatever reason (sheer luck?), we only observed a handful of (integer) values.</p>
<p><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-77-1.png" width="672"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-77-2.png" width="672"></p>
<p>Notice that this is <em>not</em> how we think participants behave. I think everyone<a href="ordered-categorical-data-i.e.-likert-scales.html#fn35" class="footnote-ref" id="fnref35"><sup>35</sup></a> would object to the idea that the limited repertoire of responses is due to endogenous processing rather than exogenous limitations imposed by an experimental design. Yet, this is how a <em>linear model</em> thinks about it (given the outcome variable you gave it) and, if you are not careful, it is easy to miss this change in the narrative. It is, however, important as it means that estimates produced by such model are about that alternative one-to-one kind of responses, not the many-to-one that you had in mind! That alternative is not a bad story per se, it is just a <em>different</em> story that should not be confused with the original one.</p>
<p>This change in the narrative of what responses correspond to is also a problem if you want to use a (fitted) linear model to simulate the data. It will happily spit out real valued responses like 6.5, 3.14, or 2.71828 (if you feel lucky enough to expect an actual integer response, you’d better use this luck on playing an actual lottery). You have two options. First, you bite the bullet and take them at their face value, sticking to “response is a real-valued variable” and one-to-one mapping between an internal variable and an observed response. That let’s you keep the narrative but means that real and ideal observers play by different rules. Their responses are different and that means your conclusions based on an ideal observer behavior are of limited use. Alternatively, you can round real-valued responses off to a closest integer getting discrete categorical-like responses. Unfortunately, that means changing the narrative yet again. In this case, you fitted the model assuming one-to-one mapping but you use its predictions assuming many-to-one. Not good. It is really hard to understand what is going on, if you keep changing your mind on what a response means. A linear model will also generate out-of-range responses, like -1 or 8. Here, you have little choice but to clip them into the valid range, forcing the many-to-one mapping on at least some responses. Again, change of a narrative means that model fitting and model interpretation rely on different conceptualizations of what response is.</p>
<p>This may sound too conceptual but I suspect that few people, who use linear models on Likert-scale data directly, realize that their model is not doing what they think it is doing and, erroneously!, interpret one-to-one linear-model estimates as many-to-one. The difference may or may not be crucial but the question is: Why employ a model that does something different to what you need to? Remember, using an appropriate model and interpreting it correctly is <em>your</em> job, not that of a mathematical model or nor is it a job of a software package.</p>
</div>
<div id="a-technical-problem-data-that-bunches-up-near-a-range-limit." class="section level2" number="18.3">
<h2>
<span class="header-section-number">18.3</span> A technical problem: Data that bunches up near a range limit.<a class="anchor" aria-label="anchor" href="#a-technical-problem-data-that-bunches-up-near-a-range-limit."><i class="fas fa-link"></i></a>
</h2>
<p>When you use a linear model, you assume that residuals are normally distributed. This is something that you may not be sure of <em>before</em> you fit a specific model, as it is residuals not the data that must be normally distributed. However, in some cases you may be fairly certain that this will not be the case, such as when a variable has only a limited range of values and the mean (the model prediction) is close to one of these limits. Whenever you have observations that are close to that hard limit, they will “bunch up” against it because they cannot go lower or higher than that. See the figure below for an illustration of how it happens if a <em>continuous</em> variable <span class="math inline">\(x\)</span> is restricted to 1 to 7 range<a href="ordered-categorical-data-i.e.-likert-scales.html#fn36" class="footnote-ref" id="fnref36"><sup>36</sup></a>.
<img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-78-1.png" width="672"></p>
<p>The presence of a limit is not a deal breaker for using linear models per se. Most physical measures cannot be negative<a href="ordered-categorical-data-i.e.-likert-scales.html#fn37" class="footnote-ref" id="fnref37"><sup>37</sup></a> but as long your observations are sufficiently far away from zero, you are fine. You cannot have a negative height but you certainly can use linear models for adult height as, for example, an average female height in USA 164±6.4 cm. In other words, the mean is more than 25 standards deviations away from the range limit of zero and the latter can be safely ignored.</p>
<p>Unfortunately, Likert-scale data combines an extremely limited range with a very coarse step. Even a 7-point Likert scale does not give you much of a wiggle room and routinely used 5-point scales are even narrower. This means that unless the mean is smack in the middle (e.g., at four for a 7-point scale) and the distribution is very narrow, you are getting closer to one of the limits and your residuals become either positively (when approaching a lower limit) or negatively (for the upper one) skewed. In other words, the residuals are <em>systematically</em> not normally distributed and their distributions depends on the mean. This clearly violates an assumption of normality of residuals and of their conditional i.i.d. (Independent and Identically Distributed). This is a deal breaker for parametric frequentist statistics (a <em>t</em>-test, a repeated-measures ANOVA, linear-mixed models), so that inferences become unreliable and should not to be trusted.</p>
</div>
<div id="another-technical-problem-can-we-assume-that-responses-correspond-to-real-numbers-that-we-picked" class="section level2" number="18.4">
<h2>
<span class="header-section-number">18.4</span> Another technical problem: Can we assume that responses correspond to real numbers that we picked?<a class="anchor" aria-label="anchor" href="#another-technical-problem-can-we-assume-that-responses-correspond-to-real-numbers-that-we-picked"><i class="fas fa-link"></i></a>
</h2>
<p>The skewed residuals described above are a fundamental problem for parametric frequentist methods but is not critical if you use Bayesian or non-parametric bootstrapping/permutation linear models. Does this mean it is safe to use them? Probably not. When you use responses directly, you assume a direct correspondence between a response label (e.g., “agree”) and a real number <span class="math inline">\(4.0\)</span>. If that is the case, you can assume that <span class="math inline">\((4 + 4) / 2\)</span> is equal to <span class="math inline">\((3 + 5) / 2\)</span> to <span class="math inline">\((2 + 6) / 2\)</span> to <span class="math inline">\((1 + 7)/ 2\)</span>. However, what if this is <em>not</em> the case, what if the cut-points (responses) do not correspond to the real numbers that you’ve picked? Then our basic arithmetic stops working the way you think! Take a look at the figure below where “real value” of responses is not an integer.</p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-79-1.png" width="672"></div>
<p>Unless you <em>know</em> response levels correspond to the selected real number and that the simple arithmetic holds, you are in danger of computing nonsense. This problem is more obvious when individual response levels are labelled, e.g., <code>"Strongly disagree"</code>, <code>"Disagree"</code>, <code>"Neither disagree, nor agree"</code>, <code>"Agree"</code>, <code>"Strongly agree"</code>. What is an average of <code>"Strongly disagree"</code> and <code>"Strongly agree"</code>? Is it the same as an average of <code>"Disagree"</code> and <code>"Agree"</code>? Is increase from <code>"Strongly disagree"</code> to <code>"Disagree"</code> identical to that from <code>"Neither disagree, nor agree"</code> to <code>"Agree"</code>? The answer is “who knows?!” but in my experience scales are rarely truly linear as people tend to avoid extremes and have their own idea about range of internal variables levels that correspond to a particular response.</p>
<p>As noted above, even when scale levels are explicitly named, it is very common to “convert” them to numbers because you cannot ask computer to compute an average of <code>"Disagree"</code> and <code>"Agree"</code> (it will flatly refuse to do this) but it will compute an average of <span class="math inline">\(2\)</span> and <span class="math inline">\(4\)</span>! And the will be no error! And it will return <span class="math inline">\(3\)</span>! Problem solved, right? Not really. Yes, the computer will not complain but this is because it has no idea what <span class="math inline">\(2\)</span> and <span class="math inline">\(4\)</span> stand for, you give it real numbers, it will do the math. So, if you pretend that <code>"Disagree"</code> and <code>"Agree"</code> correspond directly to <span class="math inline">\(2\)</span> and <span class="math inline">\(4\)</span> it will certainly <em>look like</em> normal math. And imagine that the numbers are <span class="math inline">\(2\)</span> and <span class="math inline">\(5\)</span> (so, <code>"Disagree"</code> and <code>"Strongly agree"</code>), the computer will return an average value of <span class="math inline">\(3.5\)</span> and it will be even easier to convince yourself that your responses are real numbers (see, there is a <em>decimal point</em> where!), just like linear models assume. Unfortunately, you are not fooling the computer (it seriously does not care), you are fooling yourself. Your math might check out, if responses do correspond to the real numbers you’ve picked, or it might not. And there will be no warning or an error, just some numbers that you will interpret at face value and reach possibly erroneous conclusions. Again, the problem is that you wouldn’t know whether the numbers you are looking at are valid or nonsense and the same dilemma (valid or nonsense?) will be applicable to any inferences and conclusions that you draw from them. In short, a direct correspondence between response levels and specific real numbers is a <em>very</em> strong assumption that should be validated, not taken on pure faith.</p>
</div>
<div id="solution-an-ordered-logitprobit-model" class="section level2" number="18.5">
<h2>
<span class="header-section-number">18.5</span> Solution: an ordered logit/probit model<a class="anchor" aria-label="anchor" href="#solution-an-ordered-logitprobit-model"><i class="fas fa-link"></i></a>
</h2>
<p>Above I have summarized the problems of using linear models when assuming that responses correspond to real numbers. Instead, you should use ordered <a href="https://en.wikipedia.org/wiki/Ordered_logit">logistic</a>/<a href="https://en.wikipedia.org/wiki/Ordered_probit#:~:text=In%20statistics%2C%20ordered%20probit%20is,fair%2C%20good%2C%20excellent">probit</a>.) models. They are built using the many-to-one mapping conceptualization using a set of cut-points. The latter can be fixed or, better still, fitted as part of the model. Both models assume that the distribution of the underlying continuous variable is normal and, therefore, both the continuous variable and cut points live on the infinite real number line that is transformed to 0..1 range via either logit or probit link function. The latter step is, strictly speaking, not necessary but makes it easier to understand relative positions of cut points and changes in continuous variable (that we translate into discrete responses via cut points).</p>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-80-1.png" width="672"></div>
<div class="inline-figure"><img src="notes-on-statistical-rethinking_files/figure-html/unnamed-chunk-81-1.png" width="672"></div>

</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr>
<ol>
<li id="fn1"><p>Although, if you skip episode 1, you won’t know why it is <em>obvious</em> that area of a circle is <span class="math inline">\(\pi\cdot r^2\)</span><a href="loss-functions.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>I’ve nicked the derivations from [<a href="https://stats.stackexchange.com/a/312997" class="uri">https://stats.stackexchange.com/a/312997</a>]<a href="loss-functions.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Dear electric engineers, yes, I know that’s not quite how it works but it is still a good metaphor!<a href="directed-acyclic-graphs-and-causal-reasoning.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>If you feel that science is not about guessing, you are wrong and I have Richard Feynman on my side! You always start by guessing a particular law or rule and then use empirical data to check whether your guess was correct. If you made an <em>educated</em> guess, your chances of it being correct are higher, so your job is to study the field and prior work to make your guess as educated as possible. But, at the end, it is still a guess and it can be wrong. Good news, at least in my experience, is that guesses that turn out to be spectacularly wrong are the most informative ones, as they reveal something unexpected and, thus, hitherto unknown about the process.<a href="directed-acyclic-graphs-and-causal-reasoning.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>The data is “standardized”, therefore, age of 1 is one standard deviation away from the mean marriage rate.<a href="directed-acyclic-graphs-and-causal-reasoning.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>As you will learn later, the opposite is also true, so you can turn independence into conditional dependence.<a href="directed-acyclic-graphs-and-causal-reasoning.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>Don’t be like me, be better!<a href="spurious-association.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>I’ve made priors for both betas broad, so that they are not pushed towards zero too aggressively and uncertainty about them is more evident<a href="spurious-association.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>I’ve dropped likelihood and variance only to compress formulas and shed unimportant details. Adding them does not change the essence.<a href="spurious-association.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>in our case, the difference, because we defined that <code>M = -A</code>.<a href="spurious-association.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>I’ve used ordinary least squares just to make simulations faster. You will get the same result using Bayesian fittings procedures.<a href="spurious-association.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>It is true only in a sense that it matches the processes of creating the data. It is <em>not</em> necessarily truly true for real data!<a href="spurious-association.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>“Just tell me how things are!”<a href="spurious-association.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>In general, changed depending on the effect signs of individual effects.<a href="the-haunted-dag.html#fnref14" class="footnote-back">↩︎</a></p></li>
<li id="fn15"><p>Mathematically equivalent but the sum of logs is far more numerically stable.<a href="information-criteria.html#fnref15" class="footnote-back">↩︎</a></p></li>
<li id="fn16"><p>I did not follow the derivation of that correspondence yet, so I cannot comment on how and why.<a href="information-criteria.html#fnref16" class="footnote-back">↩︎</a></p></li>
<li id="fn17"><p>Almost, the minor difference is whether you use the entire posterior averaging over samples (DIC, WAIC, PSIS-LOO) or only a single maximum a posteriori sample (AIC, BIC).<a href="information-criteria.html#fnref17" class="footnote-back">↩︎</a></p></li>
<li id="fn18"><p>And the one you should use to actually compute it, as it offers a better computation stability.<a href="information-criteria.html#fnref18" class="footnote-back">↩︎</a></p></li>
<li id="fn19"><p>McElreath writes that “BIC…it’s not actually an “information criterion.”“. So far, I was not able to figure out why.<a href="information-criteria.html#fnref19" class="footnote-back">↩︎</a></p></li>
<li id="fn20"><p>It was used during a super-secret meeting in Stanislaw Lem’s Eleventh Voyage of Ijon Tichy, so that no one would hear when they ring that bell!<a href="information-criteria.html#fnref20" class="footnote-back">↩︎</a></p></li>
<li id="fn21"><p>A canonical example is using importance ratios to sample tails of a distribution, which you have access to but the data points from tails comes up by chance so rarely that sampling them directly is very inefficient.<a href="information-criteria.html#fnref21" class="footnote-back">↩︎</a></p></li>
<li id="fn22"><p>Not really.<a href="bayesian-vs.-fequentist-statisics.html#fnref22" class="footnote-back">↩︎</a></p></li>
<li id="fn23"><p>Admittedly, in this case people often start with the statistical test and see whether data is suitable rather than the other way around.<a href="bayesian-vs.-fequentist-statisics.html#fnref23" class="footnote-back">↩︎</a></p></li>
<li id="fn24"><p>However, you do see cases when one simply throws all factors and interactions into the pot with little regard for an underlying causal model or interpretability of the coefficients.<a href="bayesian-vs.-fequentist-statisics.html#fnref24" class="footnote-back">↩︎</a></p></li>
<li id="fn25"><p>Modern packages like <em>brms</em> make it easy for you by deducing a set of reasonable priors for you. However, it is always a good idea to double-check them.<a href="bayesian-vs.-fequentist-statisics.html#fnref25" class="footnote-back">↩︎</a></p></li>
<li id="fn26"><p>In my experience, people tend to worry about priors for data unseen. Some kind of data of which you know absolutely nothing, hence, have trouble deducing priors. In practice, you always know something about the topic and the data. If not, you should read on it instead of using flat priors!<a href="bayesian-vs.-fequentist-statisics.html#fnref26" class="footnote-back">↩︎</a></p></li>
<li id="fn27"><p>As Hook’s law is a first-order linear approximation, this metaphor works fully only if we assume L1 distance, i.e., that error increases / probability decreases linearly with distance. Still you could imagine a better rubber band whose force will be proportional to the squared (L2) distance, as for the normal likelihood.<a href="incorporating-measurement-error-a-rubber-band-metaphor.html#fnref27" class="footnote-back">↩︎</a></p></li>
<li id="fn28"><p>You can find them all in a <a href="https://www.routledge.com/Generalized-Additive-Models-An-Introduction-with-R-Second-Edition/Wood/p/book/9781498728331">book</a> by Simon N. Wood.<a href="generalized-additive-models-as-continuous-random-effects.html#fnref28" class="footnote-back">↩︎</a></p></li>
<li id="fn29"><p>Note that <code><a href="https://rdrr.io/r/stats/cor.html">var()</a></code> function in R does not compute variance of the sample but is an estimator, so it applies the correction automatically. If you want variance of the sample itself, you need to undo the correct or write your own function.<a href="unbiased-mean-versus-biased-variance-in-plain-english.html#fnref29" class="footnote-back">↩︎</a></p></li>
<li id="fn30"><p>Assuming that sampling distribution for the mean is approximately normal.<a href="unbiased-mean-versus-biased-variance-in-plain-english.html#fnref30" class="footnote-back">↩︎</a></p></li>
<li id="fn31"><p>This is effectively a definition of the mean, take a look at the notes on loss functions to see why this is the case<a href="unbiased-mean-versus-biased-variance-in-plain-english.html#fnref31" class="footnote-back">↩︎</a></p></li>
<li id="fn32"><p>People tend to be scared of calculus which is all about limits when things become either infinitesimally small or large.<a href="probability-mass-versus-probability-density.html#fnref32" class="footnote-back">↩︎</a></p></li>
<li id="fn33"><p>Keep in mind that these values are based on our example of me building a tower. In other circumstances, negative values are possible.<a href="probability-mass-versus-probability-density.html#fnref33" class="footnote-back">↩︎</a></p></li>
<li id="fn34"><p>Here, I will assume that cut-points are fixed and it is parameters of the normal distribution that get adjusted. The actual implementation of ordered logit/probit models has it other way around, so that intensity always comes from a normal distribution centered at <span class="math inline">\(0\)</span> and with a standard deviation of <span class="math inline">\(1\)</span> and it is cut-points that get adjusted. The two are mathematically equivalent but I find the former to be more intuitive.<a href="ordered-categorical-data-i.e.-likert-scales.html#fnref34" class="footnote-back">↩︎</a></p></li>
<li id="fn35"><p>Never say always!<a href="ordered-categorical-data-i.e.-likert-scales.html#fnref35" class="footnote-back">↩︎</a></p></li>
<li id="fn36"><p>Note that for skewed distributions their mode is different from the mean!<a href="ordered-categorical-data-i.e.-likert-scales.html#fnref36" class="footnote-back">↩︎</a></p></li>
<li id="fn37"><p>Try coming up with one and don’t say “temperature”!<a href="ordered-categorical-data-i.e.-likert-scales.html#fnref37" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="multiple-regression---masked-relationship.html"><span class="header-section-number">17</span> Multiple regression - Masked relationship</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#ordered-categorical-data-i.e.-likert-scales"><span class="header-section-number">18</span> Ordered Categorical Data, i.e., Likert-scales</a></li>
<li><a class="nav-link" href="#conceptualization-of-responses-internal-continuous-variable-discritized-into-external-responses-via-a-set-of-cut-points"><span class="header-section-number">18.1</span> Conceptualization of responses: internal continuous variable discritized into external responses via a set of cut-points</a></li>
<li><a class="nav-link" href="#conceptual-problem-with-linear-models-we-change-our-mind-about-what-responses-correspond-to."><span class="header-section-number">18.2</span> Conceptual problem with linear models: we change our mind about what responses correspond to.</a></li>
<li><a class="nav-link" href="#a-technical-problem-data-that-bunches-up-near-a-range-limit."><span class="header-section-number">18.3</span> A technical problem: Data that bunches up near a range limit.</a></li>
<li><a class="nav-link" href="#another-technical-problem-can-we-assume-that-responses-correspond-to-real-numbers-that-we-picked"><span class="header-section-number">18.4</span> Another technical problem: Can we assume that responses correspond to real numbers that we picked?</a></li>
<li><a class="nav-link" href="#solution-an-ordered-logitprobit-model"><span class="header-section-number">18.5</span> Solution: an ordered logit/probit model</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/alexander-pastukhov/notes-on-statistics/blob/master/17-ordered-categorical.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/alexander-pastukhov/notes-on-statistics/edit/master/17-ordered-categorical.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Notes on Statistics</strong>" was written by Alexander Pastukhov. It was last built on 2022-04-08.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
